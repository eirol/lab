{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2022-04-23T16:31:16+00:00"
    },
    {
      "path": "index.html",
      "title": "Your title here",
      "description": "So, this is what this looks like.\n",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2022-04-23T16:31:17+00:00"
    },
    {
      "path": "trends.html",
      "title": "Compute Trends Across Three eras of Machine Learning",
      "description": "by Jsevillamol, Pablo Villalobos, lennart, Marius Hobbhahn, Tamay Besiroglu, anson.ho\n",
      "author": [],
      "contents": "\nWhat do you need to develop advanced Machine Learning systems? Leading companies don’t know. But they are very interested in figuring it out. They dream of replacing all these pesky workers with reliable machines who take no leave and have no morale issues.\nSo when they heard that throwing processing power at the problem might get you far along the way, they did not sit idly on their GPUs. But, how fast is their demand for compute growing? And is the progress regular?\nEnter us. We have obsessively analyzed trends in the amount of compute spent training milestone Machine Learning models.\nOur analysis shows that:\nBefore the Deep Learning era, training compute approximately followed Moore’s law, doubling every ≈20 months.\nThe Deep Learning era starts somewhere between 2010 and 2012. After that, doubling time speeds up to ≈5-6 months.\nArguably, between 2015 and 2016 a separate trend of large-scale models emerged, with massive training runs sponsored by large corporations. During this trend, the amount of training compute is 2 to 3 orders of magnitude (OOMs) bigger than systems following the Deep Learning era trend. However, the growth of compute in large-scale models seems slower, with a doubling time of ≈10 months.\nFigure 1: Trends in n=118 milestone Machine Learning systems between 1950 and 2022. We distinguish three eras. Note the change of slope circa 2010, matching the advent of Deep Learning; and the emergence of a new large scale trend in late 2015.Table 1. Doubling time of training compute across three eras of Machine Learning. The notation [low, median, high] denotes the quantiles 0.025, 0.5 and 0.975 of a confidence interval.Not enough for you? Here are some fresh takeaways:\nTrends in compute are slower than previously reported! But they are still ongoing. I’d say slow and steady, but the rate of growth is blazingly fast, still doubling every 6 months. This probably means that you should double the timelines for all previous analyses that relied on AI and Compute’s previous result.\nWe think the framing of the three eras of ML is very helpful! Remember, we are suggesting to split the history of ML into the Pre-Deep Learning Era, the Deep Learning Era and the Large-Scale Era. And we think this framing can help you make sense of what has happened in the last two decades of ML research.\nWe have curated an awesome public database of milestone ML models! Please use it for your own analyses (don’t forget to cite us!). If you want to play around with the data, we are maintaining an interactive visualization of it here and a crappier but ligther one here.\nCompute is a strategic resource for developing advanced ML models. Better understanding the progress of our compute capabilities will help us better navigate the advent of transformative AI.\nIn the future, we will also be looking at the other key resource for training machine learning models: data. Stay tuned for more!\nRead the full paper now on the arXiv\n\n\n\n",
      "last_modified": "2022-04-23T16:31:17+00:00"
    }
  ],
  "collections": []
}
